<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Strong or General Collective Intelligence">
    <title>Strong or General Collective Intelligence</title>
</head>
<body>

    <!-- Header -->
    <header>
        <img src="CTWUC-logo.jpg" alt="Change the World University Challenge Logo">
        <h1>Change the World University Challenge</h1>
    </header>

    <!-- Navigation Menu -->
    <nav>
        <a href="index.html">Home</a>
        <a href="about.html">About</a>
        <a href="resources.html">Resources</a>
        <a href="sponsors.html">Sponsors</a>
        <a href="events.html">Events</a>
        <a href="news.html">News</a>
        <a href="publications.html">Publications</a>
    </nav>

    <!-- Main Content -->
    <section class="content">
        <h2>Strong or General Collective Intelligence</h2>
        <p>There are many theoretical explorations of the limits to the complexity of problems that can be solved computationally. However, there is limited study of the innate limits of human groups with regards to the complexity of problems for which an optimal definition of the problem is reliably achievable, and/or for which an optimal solution can reliably be discovered.
</p>
<p>
There also has been little study regarding the concept of a general or “strong” collective intelligence (strong CI) and its relationship to these innate human limits. In the emerging field of collective intelligence (CI), the concept of general or "strong CI" as opposed to conventional CI which is narrow or “weak CI” in comparison, parallels the idea of general or strong artificial intelligence as opposed to narrow or weak AI. In analogy with strong AI, strong CI embodies the ability to tackle a broad range of problems beyond narrowly defined domains. Furthermore, unlike individual general intelligence, such as that in humans or that in any hypothetical artificial general intelligence (AGI) software, each of which are posited to optimize outcomes from a single perspective, strong CI seeks optimal outcomes from the perspective of each member of the entire group. Well established works provide a clear operational definition for the concept of strong AI, and a detailed exploration of how it might be measured (Bostrom, 2014; Goertzel, B., & Pennachin, 2014). Through the analogy between strong AI and strong CI, these works offer insight into operationalizing the definition of strong CI, particularly within groups of intelligent agents that can be considered independently of complexities such as emotion, as well as offering insight into how strong CI might be measured. However, this consideration of non-emotional agents is only intended to outline the simplest case in order to communicate how strong CI might achieve clarity and control in decision-making. It is in no way intended to suggest limits to the applicability of the insights offered by this perspective article with respect to the performance of human groups.
</p>
<p>
Two clear examples of problems that exceed this limit of complexity can readily be defined. One is that groups that presumably lack strong CI (that don’t explicitly have a solution that provides strong CI) are reliably unable to discover solutions that are optimal when “network effects” are considered. Networks of solutions that cooperate can achieve vastly or even exponentially greater impact on collective outcomes than solutions that compete for impact on their own. Circular economies that combine a set of activities of different businesses in order to increase impact on some outcome such as sustainability are examples of network effects. The concept of circular economies isn’t new, however the concept of using mathematical tools such as Generalized Nets to discover new networks of cooperating organizations that maximize a given economic or other outcome is relatively unexplored, even though Generalized Nets have long been applied to optimizing existing networks such as supply chains.
</p>
<p>
Another example is that groups that presumably lack strong CI are reliably unable to switch between optimal problem-solving domains in some cases. According to the theory of the lateralization of brain function, the human brain has two distinct parts, the left hemisphere and the right hemisphere, each of which specializes in different functions, processes information in different ways, and influences behavior in its unique manner. In an analogous manner, the collective social brain hypothesis posits that individuals in one hemisphere of the collective social brain tend to reason using system I or intuitive reasoning that prioritizes consensus in matters of social protection and provision where they perceive themselves as vulnerable, and that individuals in the other hemisphere of the collective social brain tend to reason using system II or rational methodical reasoning that prioritizes independent thinking in matters of social protection and provision where they don’t perceive value in seeing themselves as vulnerable. These reasoning strategies are hypothesized to simply come up with different answers given the exact same information and in large groups that lack the mechanism to switch between these two strategies (which it is hypothesized only exists in small groups connected by tight social bonds) the more information that is shared the more these groups polarize. 
</p>
<p>
Both reasoning strategies are potentially useful however. Consensus is a pattern, and reasoning that is based on patterns that identify solutions observed in the past is necessary where solutions to problems are uncomputable. This pattern recognition is the domain of AI. Examples of solutions in which consensus is useful are those addressing high signal to noise problems where the solution is distributed across the group. Logical reasoning might be necessary however where solutions are computable. Examples are low signal to noise problems where the solution might reside in as few as a single individual in the group. This is the domain of procedural software programs. It is the ability of groups to switch between these reasoning strategies depending on which is optimal, that in part defines “strong CI”.
</p>
<p>
The lack of strong CI is predicted to set innate limits to the ability of human groups to correctly define problems or to discover the correct solutions as a result of their inability to collectively identify the optimal problem-solving domain. This in turn is predicted to prevent computing problems from reliably being correctly defined and/or prevent solutions reliably being discovered past these limits. As an example, according to this hypothesis, when tackling challenges such as AI safety, disinformation, or any other phenomenon that differs radically depending on which side of the “collective social brain” which one perceives the issue from, groups and therefore any problem-solving efforts by those groups, cannot reliably define the problem correctly or discover the correct solution.
</p>
<p>
As a specific case, individuals who assess what is “safe” AI behavior or what is disinformation according to consensus, and who attempt to impose that consensus everywhere, might come up with a completely opposite viewpoint as compared to those who assess what is “safe” AI behavior or what is disinformation according to their own independently executed logic, which they might attempt to impose everywhere as well. Both of these strategies competing to impose themselves everywhere is hypothesized to have the effect of causing the group decision-making to prioritize individual competition to centralize decision-making control, rather than optimizing the outcome of collective problem-solving. A General Collective Optimization (GCO) strategy on the other hand maximizes the group’s fitness to execute all of its functions.
</p>
<p>
Furthermore, the limits to the problem-solving ability of human groups appear to largely be invisible since a search of the literature shows that the concept of the collective social brain and this associated switching problem are virtually unknown. In addition, identification of errors related to the lack of strong CI are obfuscated by the complexity of the problems themselves and hence the deep subject matter expertise required to understand them. In other words, in practice, in attempting to spread this knowledge to computing, physics, mathematics, biology, economics, or any other disciplines, it has not yet been proved sufficient for any one individual to learn about these limits and communicate them to all these disciplines. If these limits cannot be readily generalized and methodically identified everywhere, then individual experts in each such discipline will have to learn these limits and identify them on an ad hoc basis per discipline.
</p>
<p>
Part of strong CI is hypothesized to be the ability to fulfill the General Collective Optimization or GCO function in group decision-making, which refers to a function that enables a group of individual humans and/or other intelligent agents to optimize a specific outcome or range of outcomes relevant to the entire group.
</p>
<p>
Where networks of cooperating interventions have the potential to achieve far greater impact on collective outcomes than any stand-alone intervention competing with other interventions for impact on its own, a GCO function aims to enable a group of users of different roles to reliably converge on selecting the network of interventions that is most fit in optimizing a collectively targeted outcome. In living organisms, such networks might increase collective impact to the point it might become self-sustaining with the inputs that are available in the local environment. In computing, such network effects might be applied to define a vastly greater number of potential problem definitions, or to discover a vastly greater number of potential algorithms to solve those problems, in order to assess which might be collectively optimal.
</p>
<p>
The innate limits to the ability of human groups to correctly define problems or to discover the correct solutions in the absence of strong collective intelligence are potentially best understood as the inability to resolve one proposed solution as being better (more fit at achieving some collective outcome) than another, where the optimal solution lies in the difference. In other words, past the limits of the group to navigate complexity, there is too much noise to clearly discern the correct solution.
</p>
<p>
These limits, if they can be confirmed to exist, and if they can be confirmed to place limits on the ability of human groups to optimally define and solve problems regardless of the raw computational power available, suggest that this alternate line of inquiry might be a profoundly important one when it comes to mankind’s most existential challenges.</p>
    </section>

    <!-- Footer -->
    <footer>
        <p>&copy; 2024 Change the World University Challenge. All Rights Reserved.</p>
    </footer>

</body>
</html>
